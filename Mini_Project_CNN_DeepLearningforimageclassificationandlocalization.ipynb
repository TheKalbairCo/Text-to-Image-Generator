{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheKalbairCo/VisionsystemProject/blob/main/Mini_Project_CNN_DeepLearningforimageclassificationandlocalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oq2MJLoPZ-v",
        "outputId": "4b7fe0eb-8d84-4ba4-a38d-0f44cf8ff491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SNezC38O28Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "690NRIMZ3BYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehBfTuNB3BwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU-mozVsPvNC",
        "outputId": "7b175079-3a25-414b-b3fa-9b45ff1ab7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-cv\n",
            "  Downloading keras_cv-0.6.4-py3-none-any.whl (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.1/803.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-cv) (23.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-cv) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv) (2023.6.3)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv) (4.9.3)\n",
            "Collecting keras-core (from keras-cv)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (13.5.3)\n",
            "Collecting namex (from keras-core->keras-cv)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-cv) (0.1.8)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.5.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (2.3.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (4.66.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv) (1.15.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (6.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (4.5.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-cv) (2.16.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.60.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
            "Installing collected packages: namex, keras-core, keras-cv\n",
            "Successfully installed keras-core-0.1.7 keras-cv-0.6.4 namex-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install keras-cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QERx0vFOQEfh",
        "outputId": "7359a1ef-ae64-41bd-9f59-b6e1c67962c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 7s 0us/step\n",
            "Training data shape: (50000, 32, 32, 3)\n",
            "Training labels shape: (50000, 10)\n",
            "Testing data shape: (10000, 32, 32, 3)\n",
            "Testing labels shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "#10 classes in the dataset are:\n",
        "#airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Preprocessing\n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Print dataset shapes\n",
        "print('Training data shape:', x_train.shape)\n",
        "print('Training labels shape:', y_train.shape)\n",
        "print('Testing data shape:', x_test.shape)\n",
        "print('Testing labels shape:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hws53yKwR91Z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU9HWP1xR1T-"
      },
      "outputs": [],
      "source": [
        "# Define CNN architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3heB9TQSEKi"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuRhm6vMSFdP",
        "outputId": "5ef30c18-9c12-4292-cc09-c1704bebf8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 1.7042 - accuracy: 0.3666 - val_loss: 1.3632 - val_accuracy: 0.5008\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 1.3375 - accuracy: 0.5210 - val_loss: 1.1602 - val_accuracy: 0.5888\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.1792 - accuracy: 0.5840 - val_loss: 1.0580 - val_accuracy: 0.6228\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 1.0730 - accuracy: 0.6255 - val_loss: 0.9833 - val_accuracy: 0.6501\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.9869 - accuracy: 0.6566 - val_loss: 0.9392 - val_accuracy: 0.6696\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.9309 - accuracy: 0.6759 - val_loss: 0.8983 - val_accuracy: 0.6884\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.8713 - accuracy: 0.6981 - val_loss: 0.8419 - val_accuracy: 0.7083\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.8275 - accuracy: 0.7125 - val_loss: 0.8322 - val_accuracy: 0.7073\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.7818 - accuracy: 0.7294 - val_loss: 0.8193 - val_accuracy: 0.7180\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 0.7433 - accuracy: 0.7415 - val_loss: 0.8553 - val_accuracy: 0.7027\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.7107 - accuracy: 0.7547 - val_loss: 0.8098 - val_accuracy: 0.7238\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.6835 - accuracy: 0.7620 - val_loss: 0.8112 - val_accuracy: 0.7260\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.6591 - accuracy: 0.7703 - val_loss: 0.8463 - val_accuracy: 0.7154\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.6314 - accuracy: 0.7806 - val_loss: 0.8061 - val_accuracy: 0.7277\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 0.6006 - accuracy: 0.7889 - val_loss: 0.8227 - val_accuracy: 0.7269\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5827 - accuracy: 0.7961 - val_loss: 0.8247 - val_accuracy: 0.7333\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.5577 - accuracy: 0.8055 - val_loss: 0.8192 - val_accuracy: 0.7343\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.5419 - accuracy: 0.8088 - val_loss: 0.8134 - val_accuracy: 0.7332\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.5328 - accuracy: 0.8115 - val_loss: 0.8678 - val_accuracy: 0.7292\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 0.5036 - accuracy: 0.8214 - val_loss: 0.8715 - val_accuracy: 0.7264\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c2e75a48be0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64,\n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x3Ruhp8jwOI",
        "outputId": "6c143ee5-2d01-4e4a-f901-54f169c2bb81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save model in h5 format\n",
        "model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9vL1_aJSJvD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7ea4d9c1-7907-494a-e5f9-93567f9a6c5a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6cde4dbc516e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load test image and preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/testimage.jfif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/testimage.jfif'"
          ]
        }
      ],
      "source": [
        "# Load test image and preprocess\n",
        "test_image = load_img('/content/testimage.jfif', target_size=(32, 32))\n",
        "test_image = img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "test_image = test_image / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1EHvPwfSPAO"
      },
      "outputs": [],
      "source": [
        "# Make prediction on test image\n",
        "y_pred = model.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1B7utWySRz6"
      },
      "outputs": [],
      "source": [
        "# Convert prediction to class label\n",
        "class_labels = ['airplane', 'automobile', 'bird',\n",
        "    'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "predicted_class_idx = np.argmax(y_pred)\n",
        "predicted_class_label = class_labels[predicted_class_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpLZscUjSWCa"
      },
      "outputs": [],
      "source": [
        "# Evaluate performance metrics on test set\n",
        "y_test_pred = model.predict(x_test)\n",
        "y_test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test_labels, y_test_pred_labels)\n",
        "precision = precision_score(y_test_labels, y_test_pred_labels, average='macro')\n",
        "recall = recall_score(y_test_labels, y_test_pred_labels, average='macro')\n",
        "f1 = f1_score(y_test_labels, y_test_pred_labels, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaVLasOoSd7g"
      },
      "outputs": [],
      "source": [
        "# Print performance metrics and predicted class label\n",
        "print('accuracy:', accuracy)\n",
        "print('precision:', precision)\n",
        "print('recall:', recall)\n",
        "print('f1 score:', f1)\n",
        "print('predicted class label:',predicted_class_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test image and draw bounding box with predi\n",
        "cted class label\n",
        "import\n",
        "matplotlib.pyplot\n",
        "as\n",
        "plt\n",
        "from\n",
        "google.colab.patches\n",
        "import\n",
        "cv2_imshow\n",
        "# Load test image\n",
        "image = cv2.imread(\n",
        "'/content/horsetestimage.jfif'\n",
        ")\n",
        "# Define bounding box coordinates\n",
        "x, y, w, h = 100,100,200,200\n",
        "# Draw bounding box on image\n",
        "cv2.rectangle(image, (x, y), (x+w, y+h), (0,255,0),2)\n",
        "# Add predicted class label to bounding box\n",
        "cv2.putText(image, predicted_class_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,0.9, (0,255,0),2)\n",
        "# Display image with bounding box and predicted class label\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y1p_RVsTBrHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}